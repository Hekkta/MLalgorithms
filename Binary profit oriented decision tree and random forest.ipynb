{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "750ecad9",
   "metadata": {},
   "source": [
    "This code is a bit of a mess, but in essence is quite simple. When trying to predict optimally for profit we often know exactly the benifits of choosing a class over another and the class_weight is usually used in these cases. But I found it to be sub optimal although very close. So instead of using entropy or gini this decision tree takes an input of savings and collateral (profit/loss) and chooses the nodes to maximise profits. It's very flexible and can be adjusted to work with whatever your model needs.\n",
    "\n",
    "The output for predicting is a dictionary, and so the random forest will simply create a list of dictionaries and vote on the final prediction.\n",
    "\n",
    "Major con is that this is wildly inefficient, a single decision tree is taking me about 3 minutes to train on a 30 by 200,000 dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7927868d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "107d5755",
   "metadata": {},
   "outputs": [],
   "source": [
    "class dt():\n",
    "    def __init__(self, **kwargs):\n",
    "        self.split_d = {}\n",
    "        self.saving = 8\n",
    "        self.collateral = 72\n",
    "        self.max_depth = kwargs.get('max_depth', 2)\n",
    "        self.random_subset = kwargs.get('random_subset', 1)\n",
    "        if (self.random_subset > 1) or (self.random_subset <= 0):\n",
    "            print('random_subset must be a number between 0 and 1.')\n",
    "    \n",
    "    # profit function\n",
    "    def prof(self, array):\n",
    "        if array.shape[0] == 0:\n",
    "            return 0\n",
    "        return ((array[array == 1].shape[0] * self.collateral) - (array.shape[0] * self.saving))\n",
    "    \n",
    "    # profit gain function\n",
    "    def prof_gain(self, X, y, split_point):\n",
    "        return self.prop2(X, split_point)*self.prof(y[X <= split_point])\n",
    "\n",
    "    # find best split\n",
    "    def fbs(self, X, y):\n",
    "        # top split is [profit upper, profit lower, feature (int), feature split]\n",
    "        top_split = np.zeros(4)\n",
    "        # cycle through each feature\n",
    "        random_features = np.random.choice(X.shape[1], size=math.ceil(X.shape[1]*self.random_subset), replace=False)\n",
    "        print(random_features)\n",
    "        #random_rows = an_array[random_indices, :]\n",
    "        for i, x in zip(random_features, X.T[random_features,:]):\n",
    "            # cycle through each feature split\n",
    "            for f_s in np.unique(x):\n",
    "                result = self.prof(y[X.T[i] >= f_s])\n",
    "                if result > top_split[0]:\n",
    "                    top_split = [result, i, f_s, 1]\n",
    "                result = self.prof(y[X.T[i] < f_s])\n",
    "                if result > top_split[0]:\n",
    "                    top_split = [result, i, f_s, -1]\n",
    "        # returns (profit, feature number, feature split)\n",
    "        #print('top split', top_split)\n",
    "        return top_split\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        layer_list = [[]]\n",
    "        \n",
    "        self.split_d = {}\n",
    "\n",
    "        finished = False\n",
    "\n",
    "        split_id = 0\n",
    "\n",
    "        # each list in layer_list holds the splits for that layer\n",
    "        # a split has (X for that split, y for that split, feature number, feature split, split_id, direction of split)\n",
    "        layer_list[0].append((X, y, 'null', 'null', split_id, 'null'))\n",
    "\n",
    "        layer = 0\n",
    "\n",
    "        # make the decision tree\n",
    "        while not finished:\n",
    "            # add a new layer\n",
    "            layer_list.append([])\n",
    "            layer += 1\n",
    "            for split in layer_list[layer-1]:\n",
    "                \n",
    "                direction = split[5]\n",
    "                \n",
    "                split_id_temp = split[4]\n",
    "                \n",
    "                feature_number = split[2]\n",
    "                feature_split = split[3]\n",
    "\n",
    "                X_temp = split[0]\n",
    "                y_temp = split[1]\n",
    "    \n",
    "                # if only one class left then move on\n",
    "                if (len(np.unique(y_temp)) < 2) or (layer > self.max_depth):\n",
    "                    # make a leaf node with format [0, 0, 0, class_id, finished]\n",
    "                    if direction == 0:\n",
    "                        self.split_d[split_id_temp] = [0, 0, 0, 0, 0, 0, 1]\n",
    "                    else:\n",
    "                        self.split_d[split_id_temp] = [0, 1, 0, 0, 0, 0, 1]\n",
    "                    continue\n",
    "\n",
    "                # add lower split in format [profit for upper split,, profit for lower pslit, feature (int), feature split, lower split to id, upper split to id, finished]\n",
    "                split_id += 1\n",
    "                split_temp = self.fbs(X_temp, y_temp)\n",
    "                profit = split_temp[0]\n",
    "                feature = split_temp[1]\n",
    "                feature_split = split_temp[2]\n",
    "                direction2 = split_temp[3]\n",
    "                if direction2 == 1:\n",
    "                    layer_list[layer].append((X_temp[X_temp[:,feature] < feature_split], y_temp[X_temp[:,feature] < feature_split], feature, feature_split, split_id, 0))\n",
    "                    split_id += 1\n",
    "                    # add upper split (the (direction2 +1)/2 swaps the split id around depending on the direction)\n",
    "                    layer_list[layer].append((X_temp[X_temp[:, feature] >= feature_split], y_temp[X_temp[:,feature] >= feature_split], feature, feature_split, split_id, 1))\n",
    "                    self.split_d[split_id_temp] = (profit, feature, feature_split, split_id-1, split_id, direction2, 0)\n",
    "                else:\n",
    "                    layer_list[layer].append((X_temp[X_temp[:,feature] >= feature_split], y_temp[X_temp[:,feature] >= feature_split], feature, feature_split, split_id, 0))\n",
    "                    split_id += 1\n",
    "                    # add upper split (the (direction2 +1)/2 swaps the split id around depending on the direction)\n",
    "                    layer_list[layer].append((X_temp[X_temp[:, feature] < feature_split], y_temp[X_temp[:,feature] < feature_split], feature, feature_split, split_id, 1))\n",
    "                    self.split_d[split_id_temp] = (profit, feature, feature_split, split_id-1, split_id, direction2, 0)\n",
    "\n",
    "\n",
    "            if len(layer_list[-1]) == 0:\n",
    "                finished = True\n",
    "                \n",
    "    def predict(self, array):\n",
    "        result_array = []\n",
    "\n",
    "        for x in array:\n",
    "            #print('\\n', x)\n",
    "            finished = False\n",
    "            split_id = 0\n",
    "            while finished == False:\n",
    "                result = self.split_d[split_id]\n",
    "                \n",
    "                leaf_node = result[6]\n",
    "                \n",
    "                feature_number = result[1]\n",
    "                \n",
    "                feature_split = result[2]\n",
    "                \n",
    "                direction = result[5]\n",
    "                \n",
    "                top_split_id = result[3]\n",
    "                \n",
    "                bottom_split_id = result[4]\n",
    "\n",
    "                # if leaf node then end and print class\n",
    "                if leaf_node == 1:\n",
    "                    result_array.append(feature_number)\n",
    "                    #print('Complete, cat is', feature_number)\n",
    "                    break\n",
    "\n",
    "                # move on to the next split\n",
    "                if direction == 1:\n",
    "                    #print('checking if',(x[feature_number]), 'greater or equal to', (feature_split))\n",
    "                    if x[feature_number] >= feature_split:\n",
    "                        split_id = bottom_split_id\n",
    "                        #print('true, moving to', bottom_split_id)\n",
    "                    else:\n",
    "                        split_id = top_split_id\n",
    "                        #print('false, moving to', top_split_id)\n",
    "                else:\n",
    "                    #print('checking if',(x[feature_number]), 'strictly less than', (feature_split))\n",
    "                    if x[feature_number] < feature_split:\n",
    "                        split_id = bottom_split_id\n",
    "                        #print('true, moving to', bottom_split_id)\n",
    "                    else:\n",
    "                        split_id = top_split_id\n",
    "                        #print('false, moving to', top_split_id)\n",
    "\n",
    "        return np.array(result_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a99bcf8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class rf():\n",
    "    def __init__(self, **kwargs):\n",
    "        self.split_d_list = []\n",
    "        self.saving = 8\n",
    "        self.collateral = 72\n",
    "        self.max_depth = kwargs.get('max_depth', 2)\n",
    "        self.random_subset = kwargs.get('random_subset', 1)\n",
    "        if (self.random_subset > 1) or (self.random_subset <= 0):\n",
    "            print('random_subset must be a number between 0 and 1.')\n",
    "        self.n = kwargs.get('n', 10)\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        tree = dt(max_depth=self.max_depth, random_subset=self.random_subset)\n",
    "        for i in range(self.n):\n",
    "            #print('tree', i+1)\n",
    "            tree.fit(X ,y)\n",
    "            self.split_d_list.append(tree.split_d)\n",
    "            \n",
    "    def tree_predict(self, array, number):\n",
    "        result_array = []\n",
    "\n",
    "        for x in array:\n",
    "            #print('\\n', x)\n",
    "            finished = False\n",
    "            split_id = 0\n",
    "            split_d = self.split_d_list[number]\n",
    "            while finished == False:\n",
    "                result = split_d[split_id]\n",
    "                \n",
    "                leaf_node = result[6]\n",
    "                \n",
    "                feature_number = result[1]\n",
    "                \n",
    "                feature_split = result[2]\n",
    "                \n",
    "                direction = result[5]\n",
    "                \n",
    "                top_split_id = result[3]\n",
    "                \n",
    "                bottom_split_id = result[4]\n",
    "\n",
    "                # if leaf node then end and print class\n",
    "                if leaf_node == 1:\n",
    "                    result_array.append(feature_number)\n",
    "                    #print('Complete, cat is', feature_number)\n",
    "                    break\n",
    "\n",
    "                # move on to the next split\n",
    "                if direction == 1:\n",
    "                    #print('checking if',(x[feature_number]), 'greater or equal to', (feature_split))\n",
    "                    if x[feature_number] >= feature_split:\n",
    "                        split_id = bottom_split_id\n",
    "                        #print('true, moving to', bottom_split_id)\n",
    "                    else:\n",
    "                        split_id = top_split_id\n",
    "                        #print('false, moving to', top_split_id)\n",
    "                else:\n",
    "                    #print('checking if',(x[feature_number]), 'strictly less than', (feature_split))\n",
    "                    if x[feature_number] < feature_split:\n",
    "                        split_id = bottom_split_id\n",
    "                        #print('true, moving to', bottom_split_id)\n",
    "                    else:\n",
    "                        split_id = top_split_id\n",
    "                        #print('false, moving to', top_split_id)\n",
    "                \n",
    "        return np.array(result_array)\n",
    "        \n",
    "    def predict(self, array):\n",
    "        result = np.zeros(shape=(self.n, np.array(array).shape[0]))\n",
    "        for number in range(self.n):\n",
    "            result[number, :] = self.tree_predict(array, number)\n",
    "        return np.round(result.mean(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c28c1ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.datasets import make_regression\n",
    "import matplotlib.pyplot as plt\n",
    "X, y = make_blobs(n_samples=20, random_state=42, n_features=4, cluster_std=3, centers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e0a50247",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(X, columns=['x1', 'x2', 'x3', 'x4'])\n",
    "\n",
    "df['y'] = y\n",
    "\n",
    "#col = df['y'].map({1:'r', 2:'b', 0:'g'})\n",
    "\n",
    "#df.plot(kind='scatter', x='x1', y='x2', c=col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "80ee0ead",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = dt(max_depth=5, random_subset=0.4)\n",
    "\n",
    "model.fit(X, y)\n",
    "\n",
    "model.predict([[-7, -10, 1, 1], [5, 0, 10, 10], [-5, 10, -10, -10]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bfc02d2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2]\n",
      "[1 3]\n",
      "[3 1]\n",
      "[3 2]\n",
      "[1 0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1., 1., 0.])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = rf(max_depth=4, random_subset=0.5, n=5)\n",
    "\n",
    "model.fit(X, y)\n",
    "\n",
    "model.predict([[-7, -10, 1, 1], [5, 0, 10, 10], [-5, 10, -10, -10]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff20ca48",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53e60594",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
